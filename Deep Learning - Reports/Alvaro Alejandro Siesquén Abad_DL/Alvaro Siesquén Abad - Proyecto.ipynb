{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Alvaro Siesquén Abad - Proyecto.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"rMi99lerTSB8"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import matplotlib.pyplot as plt\n","import numpy as np"]},{"cell_type":"code","source":["dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"qqxVX4raTxwX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir .kaggle\n","!mv kaggle.json .kaggle/\n","!mv .kaggle ~/"],"metadata":{"id":"3BdfkjmiU2ux"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Proyecto 1: Clasificación de Imagenes"],"metadata":{"id":"PqoEZqwcTibH"}},{"cell_type":"markdown","source":["De la página [kaggle](https://www.kaggle.com/), descarguen una dataset de clasificación de imagenes. Por ejemplo:\n","- [dogs and cats dataset](https://www.kaggle.com/chetankv/dogs-cats-images).\n","- [flowers](https://www.kaggle.com/alxmamaev/flowers-recognition) \n","- [pokemon](https://www.kaggle.com/lantian773030/pokemonclassification)\n","- [American Sign Language](https://www.kaggle.com/grassknoted/asl-alphabet)\n","- [Rock, Paper, Scissors](https://www.kaggle.com/drgfreeman/rockpaperscissors)\n","\n","Pueden usar otras plataformas para buscar y descargar los datastes (como google dataset), o tambien pueden crear su propio dataset de las cosas que quisieran classificar (alrededor de 20~50 imagenes por clases estaria bien).\n","\n","Es necesario que la carpeta que contiene a las imagenes tenga el siguiente formato:\n","```\n","dataset/\n"," clase1/\n","  puede_haber_subcarpetas/\n","    imagen1.jpg\n","    imgen2.jpg\n"," clase2/\n","  solo_las_imagenes.jpg\n"," clase3/\n"," ....\n","```"],"metadata":{"id":"pLSDyyggYnw1"}},{"cell_type":"markdown","source":["## Reporte"],"metadata":{"id":"6vdREuQarJTl"}},{"cell_type":"markdown","source":["Diseñen una red neuronal para que clasifique las imagenes que se descargaron."],"metadata":{"id":"uT5pFqH9rQ1r"}},{"cell_type":"markdown","source":["**Explicar el tipo de dataset que se esta utilizando**"],"metadata":{"id":"IdQ2vxl2tZdD"}},{"cell_type":"markdown","source":[""],"metadata":{"id":"LqNaqChRtk3b"}},{"cell_type":"code","source":["# TODO: Modificar esto acorde al dataset que se va a usar\n","!kaggle datasets download chetankv/dogs-cats-images\n","!unzip dogs-cats-images.zip"],"metadata":{"id":"QfxRafDIUM16"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Si se modifica algo en la celda inferior explicar que cambios se hizo**"],"metadata":{"id":"O2bARg0_tm_L"}},{"cell_type":"markdown","source":[""],"metadata":{"id":"W8wpHAkjtwjG"}},{"cell_type":"code","source":["def evaluate(model, loader, crit):\n","  model.eval()\n","  total = 0\n","  corrects = 0\n","  avg_loss = 0\n","  for x, y in loader:\n","    x = x.to(dev)\n","    y = y.to(dev)\n","    o = model(x)\n","    loss = crit(o,y)\n","    avg_loss += loss.item()\n","    corrects += torch.sum(torch.argmax(o,axis=1) == y).item()\n","    total += len(y)\n","  acc = 100* corrects / total\n","  avg_loss /= len(loader)  \n","  return avg_loss, acc\n","\n","def train_one_epoch(model, train_loader, crit, optim):\n","  model.train()\n","  total = 0\n","  corrects = 0\n","  avg_loss = 0\n","  for x, y in train_loader:\n","    optim.zero_grad()\n","    x = x.to(dev)\n","    y = y.to(dev)\n","    o = model(x)\n","    loss = crit(o,y)\n","    avg_loss += loss.item()\n","    loss.backward()\n","    optim.step()\n","    corrects += torch.sum(torch.argmax(o,axis=1) == y).item()\n","    total += len(y)\n","  acc = 100 * corrects / total\n","  avg_loss /= len(train_loader)\n","  return avg_loss, acc\n","\n","def train(model, train_loader, test_loader, crit, optim, epochs = 20):\n","  for epoch in range(epochs):\n","    train_loss, train_acc = train_one_epoch(model, train_loader,crit, optim)\n","    test_loss, test_acc = evaluate(model, test_loader, crit)\n","    print(f\"epoch: {epoch}, train loss: {train_loss}, train acc: {train_acc}%, test loss: {test_loss}, test acc: {test_acc}%\")"],"metadata":{"id":"L8F8mmZpTwpX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Si se modifica algo en la celda inferior explicar que cambios se hizo**"],"metadata":{"id":"HLoAuafSt1xg"}},{"cell_type":"markdown","source":[""],"metadata":{"id":"yEnwfcfkt2Vi"}},{"cell_type":"code","source":["img_transform = torchvision.transforms.Compose([\n","  torchvision.transforms.RandomRotation(18),\n","  torchvision.transforms.RandomHorizontalFlip(),\n","  torchvision.transforms.Resize((224,224)),\n","  torchvision.transforms.ToTensor()\n","])"],"metadata":{"id":"lhc2opf6WULR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_ds = torchvision.datasets.ImageFolder(\"./dataset/training_set\",transform=img_transform)\n","test_ds = torchvision.datasets.ImageFolder(\"./dataset/test_set\",transform=img_transform)"],"metadata":{"id":"WHQgYqeATXQa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Esto es solo para poder ver un ejemplo de las imagenes que se estan usando\n","plt.imshow(train_ds[10][0].numpy().transpose(1,2,0))\n","plt.show()"],"metadata":{"id":"5Ntg8vOyV3Sd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Si se modifica algo en la celda inferior explicar que cambios se hizo**"],"metadata":{"id":"YLPNwMQqt6-O"}},{"cell_type":"markdown","source":["No se modificó nada"],"metadata":{"id":"hE1R770It7Xk"}},{"cell_type":"code","source":["# Esto no se necesita modificar al menos que se quiera utilizar un batch size diferente\n","# OPTIONAL:\n","# Cambiar la opción de shuffle a False y observar que pasa con los input y targets que nos brinda el dataloader, que diferencias hay?\n","# Observar que pasa con el accuracy cuando no se realiza el shuffling y explicar porque.\n","\n","train_dl = torch.utils.data.DataLoader(train_ds,batch_size=128,shuffle=True)\n","test_dl = torch.utils.data.DataLoader(test_ds,batch_size=128,shuffle=True)"],"metadata":{"id":"efOOibzzWEek"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Defina su modelo**"],"metadata":{"id":"MwGgjax1t95T"}},{"cell_type":"code","source":["model = nn.Sequential(\n","    nn.Conv2d(3,16,7,bias=False),\n","    nn.BatchNorm2d(16),\n","    nn.ReLU(inplace=True),\n","    nn.MaxPool2d(2),\n","    nn.Conv2d(16,32,3,bias=False),\n","    nn.BatchNorm2d(32),\n","    nn.ReLU(inplace=True),\n","    nn.MaxPool2d(2),\n","    nn.Conv2d(32,32,3,bias=False),\n","    nn.BatchNorm2d(32),\n","    nn.ReLU(inplace=True),\n","    nn.MaxPool2d(2),\n","    nn.Conv2d(32,64,3,bias=False),\n","    nn.BatchNorm2d(64),\n","    nn.ReLU(inplace=True),\n","    nn.MaxPool2d(2),\n","    nn.Conv2d(64,64,3,bias=False),\n","    nn.BatchNorm2d(64),\n","    nn.ReLU(inplace=True),\n","    nn.MaxPool2d(2),\n","    nn.Flatten(),\n","    nn.Linear(1024,2)\n",").to(dev)"],"metadata":{"id":"zHaeXnnFWKvP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Si se modifica algo en la celda inferior explicar que cambios se hizo**"],"metadata":{"id":"SH7sQ-APuB79"}},{"cell_type":"markdown","source":[""],"metadata":{"id":"fuXZ_SeOuCUl"}},{"cell_type":"code","source":["crit = nn.CrossEntropyLoss()\n","optim = torch.optim.SGD(model.parameters(),lr=0.1)\n","train(model,train_dl, test_dl, crit, optim, epochs=10)"],"metadata":{"id":"M_g78QfNX_nf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.eval()\n","# idx = 10\n","idx = 1000\n","x, y = test_ds[idx]\n","x_numpy = x.numpy().transpose(1,2,0)\n","N, H, W = x.shape\n","x = x.reshape(1,N,H,W)\n","pred = torch.argmax(model(x.to(dev)).cpu()).item()\n","print(pred)\n","plt.imshow(x_numpy)"],"metadata":{"id":"FpkY7uRkIaS2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.eval()\n","# idx = 10\n","for idx in (153,239,3,900,48,1178,456):\n","  x, y = test_ds[idx]\n","  x_numpy = x.numpy().transpose(1,2,0)\n","  N, H, W = x.shape\n","  x = x.reshape(1,N,H,W)\n","  pred = torch.argmax(model(x.to(dev)).cpu()).item()\n","  print(pred)\n","  plt.imshow(x_numpy)\n","  plt.show()"],"metadata":{"id":"v6mop43tvJjF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(model.state_dict(),\"proyecto1.ckpt\")"],"metadata":{"id":"xGFSLi6tE-Wp"},"execution_count":null,"outputs":[]}]}